<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Andrés Sáurez — Mechanistic Interpretability Research</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Source+Serif+4:opsz,wght@8..60,400;8..60,600;8..60,700&family=DM+Sans:wght@400;500;600&family=JetBrains+Mono:wght@400&display=swap" rel="stylesheet">
    <style>
        :root {
            --text: #1a1a1a;
            --text-secondary: #555;
            --text-tertiary: #888;
            --accent: #2d5a27;
            --accent-light: #e8f0e6;
            --bg: #fafaf8;
            --card-bg: #ffffff;
            --border: #e5e5e0;
            --serif: 'Source Serif 4', Georgia, serif;
            --sans: 'DM Sans', -apple-system, sans-serif;
            --mono: 'JetBrains Mono', monospace;
        }

        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: var(--sans);
            color: var(--text);
            background: var(--bg);
            line-height: 1.7;
            font-size: 16px;
            -webkit-font-smoothing: antialiased;
        }

        .container {
            max-width: 720px;
            margin: 0 auto;
            padding: 0 24px;
        }

        /* Header */
        header {
            padding: 80px 0 48px;
            border-bottom: 1px solid var(--border);
        }

        header h1 {
            font-family: var(--serif);
            font-size: 2.4rem;
            font-weight: 700;
            letter-spacing: -0.02em;
            margin-bottom: 8px;
        }

        .subtitle {
            font-size: 1.05rem;
            color: var(--text-secondary);
            margin-bottom: 20px;
        }

        .links {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
        }

        .links a {
            color: var(--accent);
            text-decoration: none;
            font-size: 0.9rem;
            font-weight: 500;
            display: flex;
            align-items: center;
            gap: 5px;
            transition: opacity 0.2s;
        }

        .links a:hover { opacity: 0.7; }

        .links a::before {
            content: '';
            width: 4px;
            height: 4px;
            background: var(--accent);
            border-radius: 50%;
            display: inline-block;
        }

        /* Sections */
        section {
            padding: 48px 0;
            border-bottom: 1px solid var(--border);
        }

        section:last-of-type { border-bottom: none; }

        .section-label {
            font-size: 0.75rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            color: var(--text-tertiary);
            margin-bottom: 24px;
        }

        /* Research Vision */
        .vision p {
            font-family: var(--serif);
            font-size: 1.15rem;
            line-height: 1.8;
            color: var(--text);
        }

        .vision p + p { margin-top: 16px; }

        /* Papers */
        .paper {
            background: var(--card-bg);
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 28px;
            margin-bottom: 16px;
            transition: border-color 0.2s;
        }

        .paper:hover { border-color: var(--accent); }

        .paper-title {
            font-family: var(--serif);
            font-size: 1.15rem;
            font-weight: 600;
            margin-bottom: 4px;
            line-height: 1.4;
        }

        .paper-meta {
            font-size: 0.85rem;
            color: var(--text-tertiary);
            margin-bottom: 14px;
            display: flex;
            align-items: center;
            gap: 12px;
            flex-wrap: wrap;
        }

        .paper-status {
            background: var(--accent-light);
            color: var(--accent);
            padding: 2px 8px;
            border-radius: 4px;
            font-size: 0.78rem;
            font-weight: 600;
        }

        .paper-desc {
            font-size: 0.92rem;
            color: var(--text-secondary);
            line-height: 1.7;
        }

        .paper-links {
            margin-top: 14px;
            display: flex;
            gap: 16px;
        }

        .paper-links a {
            font-size: 0.85rem;
            color: var(--accent);
            text-decoration: none;
            font-weight: 500;
        }

        .paper-links a:hover { text-decoration: underline; }

        /* Small paper card for non-primary publications */
        .paper-small {
            background: var(--card-bg);
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 20px 28px;
            margin-bottom: 12px;
            transition: border-color 0.2s;
        }

        .paper-small:hover { border-color: var(--accent); }

        .paper-small .paper-title {
            font-size: 1.02rem;
            margin-bottom: 2px;
        }

        .paper-small .paper-meta {
            margin-bottom: 0;
        }

        /* About */
        .about p {
            font-size: 0.95rem;
            color: var(--text-secondary);
            line-height: 1.8;
        }

        .about p + p { margin-top: 14px; }

        .details {
            margin-top: 28px;
            display: grid;
            grid-template-columns: 120px 1fr;
            gap: 8px 16px;
            font-size: 0.88rem;
        }

        .details dt {
            color: var(--text-tertiary);
            font-weight: 500;
        }

        .details dd { color: var(--text-secondary); }

        /* Contact */
        .contact-section p {
            font-size: 0.95rem;
            color: var(--text-secondary);
        }

        .contact-section a {
            color: var(--accent);
            text-decoration: none;
            font-weight: 500;
        }

        .contact-section a:hover { text-decoration: underline; }

        /* Footer */
        footer {
            padding: 32px 0 48px;
            text-align: center;
            font-size: 0.8rem;
            color: var(--text-tertiary);
        }

        /* Mobile */
        @media (max-width: 600px) {
            header { padding: 48px 0 32px; }
            header h1 { font-size: 1.8rem; }
            section { padding: 36px 0; }
            .paper { padding: 20px; }
            .paper-small { padding: 16px 20px; }
            .details { grid-template-columns: 1fr; gap: 4px; }
            .details dt { margin-top: 8px; }
        }
    </style>
</head>
<body>

<div class="container">

    <header>
        <h1>Andrés Sáurez</h1>
        <p class="subtitle">MS in Robotics, KAIST &middot; Mechanistic Interpretability &middot; Geometric Representations</p>
        <div class="links">
            <a href="mailto:andres.saurez95@gmail.com">Email</a>
            <a href="https://scholar.google.com/citations?user=ZwJoZ2QAAAAJ&hl=en">Google Scholar</a>
            <!-- REPLACE: Your actual GitHub link -->
            <a href="https://github.com/">GitHub</a>
        </div>
    </header>

    <section class="vision">
        <div class="section-label">Research Vision</div>
        <p>
            I study the geometric structure of how transformer models represent and manipulate concepts.
            My work argues that interpretability is fundamentally a geometric problem: semantic features
            must occupy context-invariant linear subspaces&mdash;not as an empirical regularity, but as
            a necessary consequence of how transformers communicate through linear interfaces like OV
            circuits and unembedding matrices.
        </p>
        <p>
            This perspective unifies two lines of interpretability research that have developed largely in
            isolation. Feature analysis (<em>what does the model represent?</em>) and circuit discovery
            (<em>how does the model compute?</em>) turn out to be dual operations on the same geometric
            structure: reading and writing directions in activation space. My goal is to develop this into
            a rigorous mathematical framework for understanding transformer computation.
        </p>
    </section>

    <section>
        <div class="section-label">Publications</div>

        <div class="paper">
            <div class="paper-title">Why Linear Interpretability Works: Invariant Subspaces as a Result of Architectural Constraints</div>
            <div class="paper-meta">
                <span>Andrés Sáurez, Yousung Lee, Dongsoo Har</span>
                <span class="paper-status">Under Review &middot; ICML 2026</span>
            </div>
            <div class="paper-desc">
                Why do linear probes and sparse autoencoders consistently recover meaningful structure from
                transformer representations? We prove this is a consequence of architectural necessity:
                any feature decoded through a transformer's linear interfaces (OV circuits, unembedding)
                must occupy a context-invariant subspace (Invariant Subspace Necessity theorem). We derive
                the Self-Reference Property&mdash;tokens directly encode their own feature directions&mdash;enabling
                zero-shot identification of semantic structure without labeled data or learned probes.
                Empirical validation across eight classification tasks and four model families (LLaMA3-8B,
                Mistral-7B, GPT2-Small, LLaMA3.2-3B) confirms that linear probes, SAEs, and activation
                steering all recover the same invariant directions, providing a unified architectural
                explanation for why linear interpretability methods succeed.
            </div>
            <div class="paper-links">
                <a href="https://arxiv.org/abs/2602.09783">arXiv</a>
                <!-- REPLACE: Actual links -->
                <a href="#">Code</a>
            </div>
        </div>

        <div class="paper">
            <div class="paper-title">Circuit Fingerprints: How Answer Tokens Encode Their Geometrical Path</div>
            <div class="paper-meta">
                <span>Andrés Sáurez, Neha Sengar, Dongsoo Har</span>
                <span class="paper-status">Under Review &middot; ICML 2026</span>
            </div>
            <div class="paper-desc">
                Circuit discovery and activation steering have developed as separate research threads&mdash;we
                show they follow a single geometric principle. Answer tokens, processed in isolation, encode
                the computational pathways that produce them (Circuit Fingerprint Hypothesis), enabling
                gradient-free circuit discovery from geometric alignment alone. Validated on standard
                benchmarks (IOI, SVA, MCQA) across GPT2-Small, Qwen2.5-0.5B, Llama3.2-1B, and OPT-1.3B,
                achieving performance comparable to gradient-based methods (EAP, EAP-IG). The same
                directions that identify circuit components also enable controlled steering&mdash;and can be
                extended to discover feature circuits for emotions, languages, and personas via prompt
                engineering alone, without task-specific datasets.
            </div>
            <div class="paper-links">
                <a href="https://arxiv.org/abs/2602.09784">arXiv</a>
                <!-- REPLACE: Actual links -->
                <a href="#">Code</a>
            </div>
        </div>

        <div class="paper-small">
            <div class="paper-title">Few Contrastive Attention Heads Enable Visual Grounding in Large VLMs</div>
            <div class="paper-meta">
                <span>Neha Sengar, Andrés Sáurez, Dongsoo Har</span>
                <span class="paper-status">Under Review &middot; IJCAI 2026</span>
            </div>
        </div>

        <div class="paper-small">
            <div class="paper-title">DEPLOY-RL: Active Boundary Discovery and Conservative Certification for Deployable RL in Safety-Critical Continuous Processes</div>
            <div class="paper-meta">
                <span>Yeojin Jang, Minu Baek, Gihun Gil, et al.</span>
                <span class="paper-status">Under Review &middot; IJCAI 2026</span>
            </div>
        </div>

        <div class="paper-small">
            <div class="paper-title">Continuous Adversarial Text Representation Learning for Affective Recognition</div>
            <div class="paper-meta">
                <span>Seungah Son, Andrés Sáurez, Dongsoo Har</span>
                <span class="paper-status">Published &middot; ICAIIC 2025</span>
            </div>
            <div class="paper-desc" style="margin-top: 10px;">
                A framework for enhancing emotion-aware embeddings in transformer-based models.
                Introduces continuous valence-arousal labels to guide contrastive learning (replacing
                coarse polarity labels) and a gradient-based dynamic token perturbation mechanism that
                targets sentiment-relevant tokens. Achieves up to 15.5% improvement on emotion
                classification benchmarks over baseline models, with well-separated emotional clusters
                validated through alignment-uniformity analysis.
            </div>
            <div class="paper-links">
                <a href="https://arxiv.org/abs/2502.20613">arXiv</a>
            </div>
        </div>

    </section>

    <section class="about">
        <div class="section-label">About</div>
        <p>
            I'm a Master's student in the Robotics Program at KAIST, researching mechanistic
            interpretability of transformer models with an emphasis on mathematical foundations.
            My work engages with the Linear Representation Hypothesis
            (<a href="https://arxiv.org/abs/2311.03658" style="color: var(--accent); text-decoration: none;">Park et al., 2024</a>),
            causal abstraction
            (<a href="https://arxiv.org/abs/2301.04709" style="color: var(--accent); text-decoration: none;">Geiger et al., 2024</a>),
            and geometric approaches to neural network analysis.
        </p>
        <p>
            Before KAIST, I worked as a software engineer at TransUnion, ValueLabs, and as a freelance
            ML consultant. I hold a degree in mechanical engineering and transitioned into machine learning
            research driven by an interest in understanding how intelligent systems work from the inside out.
            Originally from Costa Rica.
        </p>
        <p>
            I'm looking for research positions in mechanistic interpretability&mdash;in industry labs or
            PhD programs&mdash;where I can continue developing geometric methods for understanding and
            controlling large language models.
        </p>

        <dl class="details">
            <dt>Education</dt>
            <dd>MS Robotics, KAIST (current) &middot; BS Mechanical Engineering</dd>
            <dt>Languages</dt>
            <dd>Spanish (native) &middot; English &middot; Korean</dd>
            <dt>Previously</dt>
            <dd>TransUnion &middot; ValueLabs &middot; Upwork</dd>
            <dt>Other</dt>
            <dd>National powerlifting record holder, Costa Rica</dd>
        </dl>
    </section>

    <section class="contact-section">
        <div class="section-label">Contact</div>
        <p>
            I'm always happy to discuss interpretability research.
            Reach me at <a href="mailto:andres.saurez95@gmail.com">andres.saurez95@gmail.com</a>.
        </p>
    </section>

    <footer>
        &copy; 2026
    </footer>

</div>

</body>
</html>
